<properties
	pageTitle="확장된 기계 학습을 위한 데이터 준비 작업 | Microsoft Azure"
	description="기계 학습을 준비하기 위해 데이터를 전처리 및 정리."
	services="machine-learning"
	documentationCenter=""
	authors="bradsev"
	manager="jhubbard"
	editor="cgronlun" />

<tags
	ms.service="machine-learning"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="article"
	ms.date="09/19/2016" 
	ms.author="bradsev" />


# 확장된 기계 학습을 위한 데이터 준비 작업

데이터 전처리 및 정리는 일반적으로 기계 학습에 데이터 집합을 효과적으로 사용할 수 있기 전에 수행해야 하는 중요한 작업입니다. 원시 데이터는 노이즈가 많고, 불안정하고, 값이 누락된 경우가 종종 있습니다. 이러한 데이터를 모델링에 사용하면 결과가 잘못될 수 있습니다. 이러한 작업은 TDSP(팀 데이터 과학 프로세스)의 일부이며 일반적으로 필요한 전처리를 검색하고 계획하는 데 사용되는 데이터 집합의 초기 탐색을 수행합니다. TDSP 프로세스에 대한 자세한 지침은 [팀 데이터 과학 프로세스](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/)에 설명된 단계를 참조하세요.

데이터 탐색 작업 등의 전처리 및 정리 작업은 데이터가 저장된 위치와 포맷 방식에 따라 R 또는 Python 등의 다양한 도구 및 언어와 함께 SQL나 Hive 또는 Azure 기계 학습 스튜디오와 같은 다양한 환경에서 수행할 수 있습니다. TDSP는 반복 성향을 띠기 때문에, 이러한 작업은 프로세스의 워크플로 내의 다양한 단계에서 발생할 수 있습니다.

이 문서에서는 Azure 기계 학습에 데이터를 수집하기 전 또는 후에 수행할 수 있는 다양한 데이터 처리 개념 및 작업을 소개합니다.

Azure 기계 학습 스튜디오 내부에서 수행된 데이터 탐색 및 전처리의 예는 [Azure 기계 학습 스튜디오에서 데이터 전처리](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/) 비디오를 참조하세요.


## 데이터 전처리 및 정리가 필요한 이유

실제 데이터는 다양한 소스 및 프로세스에서 수집되며 데이터 집합의 품질을 떨어트리는 이상값 또는 손상된 값이 포함될 수 있습니다. 다음과 같은 일반적인 데이터 품질 문제가 자주 발생합니다.

* **불완전**: 데이터에 특성이 없거나 값이 누락되었습니다.
* **노이즈가 많은**: 데이터에 잘못된 레코드 또는 이상값이 있습니다.
* **불일치**: 데이터에 충돌하는 레코드 또는 일치하지 않는 값이 있습니다.

우수한 예측 모델을 구축하려면 우수한 데이터가 필요합니다. "쓰레기를 넣고 쓰레기를 얻는 현상"을 방지하고 데이터 품질을 높여서 궁극적으로 모델 성능을 높이려면 데이터 상태 검사를 수행하여 조기에 데이터 문제를 발견하고 적절한 데이터 처리 및 정리 단계를 결정하는 것이 중요합니다.

## 가장 일반적으로 사용되는 데이터 상태 검사 방법으로 어떤 것이 있습니까?

다음을 검사하여 데이터의 전체적인 품질을 확인할 수 있습니다.

* **레코드** 수.
* **특성**(또는 **기능**) 수.
* 특성 **데이터 유형**(명목, 서수 또는 연속).
* **누락된 값**의 수.
* 데이터의 **올바른 형식 여부**.
	* 데이터가 TSV 또는 CSV로 되어 있으면 열 구분 기호 및 줄 구분 기호가 열과 줄을 항상 올바르게 구분하는지 확인합니다.
	* 데이터가 HTML 또는 XML 형식이면 해당 표준에 따라 올바르게 구성되었는지 확인합니다.
	* 또한 반 구조적 데이터 또는 구조화되지 않은 데이터에서 구조적 정보를 추출하려면 구문 분석이 필요할 수 있습니다.
* **일관되지 않은 데이터 레코드**. 값의 범위가 허용되는지 확인하세요. 예를 들어 데이터에 학생 GPA가 포함되어 있으면 GPA가 지정된 범위(예: 0~4) 내에 있는지 확인합니다.

데이터 문제를 찾았으면 **처리 단계**가 필요합니다. 처리 단계에서는 누락된 값 정리, 데이터 정규화, 분할, 텍스트 처리를 통해 데이터 정렬, 공통 필드의 혼합된 데이터 유형 등에 영향을 미칠 수 있는 포함된 문자를 제거 및/또는 대체하는 작업이 주로 수행됩니다.

**Azure 기계 학습에서는 올바르게 구성된 테이블 형식 데이터를 사용합니다**. 데이터가 이미 테이블 형식이면 기계 학습 스튜디오에서 Azure 기계 학습을 사용하여 바로 데이터 전처리를 수행할 수 있습니다. 데이터가 테이블 형식이 아닌 XML 형식이라고 한다면 데이터를 테이블 형식으로 변환하려면 구분 분석이 필요할 수 있습니다.

## 데이터 전처리의 주요 작업

* **데이터 정리**: 누락된 값을 채우거나 노이즈가 많은 데이터와 이상값을 감지하여 제거합니다.
* **데이터 변환**: 데이터를 정규화하여 차원 및 노이즈를 줄입니다.
* **데이터 감소**: 데이터를 쉽게 처리할 수 있도록 데이터 레코드 또는 특성을 샘플링합니다.
* **데이터 분할**: 특정 기계 학습 방법에 쉽게 사용할 수 있도록 연속 특성을 범주 특성으로 변환합니다.
* **텍스트 정리**: 탭으로 구분된 데이터 파일에 포함된 탭, 레코드 줄 맞춤 문제를 일으킬 수 있는 포함된 새 줄 등 데이터 정렬 문제를 일으킬 수 있는 포함된 문자를 제거합니다.

아래 섹션에서는 일부 데이터 처리 단계에 대해 자세히 설명합니다.

## 누락된 값을 처리하는 방법

누락된 값을 처리하려면 누락된 값이 문제 해결에 더 나은 이유를 먼저 확인하는 것이 좋습니다. 일반적인 누락 값 처리 방법은 다음과 같습니다.

* **삭제**: 값이 누락된 레코드를 제거합니다.
* **더미 대체**: 누락된 값을 더미로 대체합니다. 예를 들어 범주 값은 _unknown_, 숫자 값은 0으로 대체합니다.
* **평균 대체**: 누락된 값이 숫자이면 평균으로 대체합니다.
* **빈도 대체**: 누락된 값이 범주이면 가장 빈도가 높은 항목으로 대체합니다.
* **회귀 대체**: 회귀 메서드를 사용하여 누락된 값을 회귀된 값으로 대체합니다.

## 데이터를 정규화하는 방법

데이터 정규화는 숫자 값을 지정된 범위로 다시 조정합니다. 일반적인 데이터 정규화 방법은 다음과 같습니다.

* **최소-최대 정규화**: 0과 1 사이에서 데이터를 선형적으로 범위로 변환합니다. 여기서 최소값은 0, 최대값은 1로 조정됩니다.
* **Z 점수 정규화**: 평균 및 표준 편차를 기반으로 데이터 조정: 데이터와 평균의 차이를 표준 편차로 나눕니다.
* **소수점 배열**: 특성 값의 소수점을 이동하여 데이터 크기를 조정합니다.

## 데이터를 분할하는 방법

연속 값을 명목 특성 또는 간격으로 변환하여 데이터를 분할할 수 있습니다. 다음은 이 작업을 수행하는 방법 중 일부입니다.

* **동일 너비 범주화**: 특성의 모든 가능한 값 범위를 크기가 같은 N개의 그룹으로 나누고 bin 번호를 사용하여 bin에 속하는 값을 할당합니다.
* **동일 높이 범주화**: 특성의 모든 가능한 값 범위를 인스턴스 수가 같은 N개의 그룹으로 나누고 bin 번호를 사용하여 bin에 속하는 값을 할당합니다.

## 데이터를 줄이는 방법

데이터를 쉽게 처리할 수 있도록 데이터 크기를 줄이는 다양한 방법이 있습니다. 데이터 크기 및 도메인에 따라 다음 방법을 적용할 수 있습니다.

* **레코드 샘플링**: 데이터 레코드를 샘플링하고 데이터에서 대표적인 하위 집합만 선택합니다.
* **특성 샘플링**: 데이터에서 가장 중요한 특성의 하위 집합만 선택합니다.
* **집계**: 데이터를 여러 그룹으로 나누고 각 그룹에 대한 숫자를 저장 합니다. 예를 들어 어떤 식당 체인의 지난 20년 간 일일 수익을 월별 수익으로 집계하면 데이터 크기를 줄일 수 있습니다.

## 텍스트 데이터를 정리하는 방법

**테이블 형식 데이터의 텍스트 필드**에 열 정렬 및/또는 레코드 경계에 영향을 미치는 문자가 포함될 수 있습니다. 예를 들어 탭으로 구분된 파일에 포함된 탭은 열 정렬 문제를 일으킬 수 있고, 포함된 새 줄 문자는 줄 맞춤 문제를 일으킬 수 있습니다. 텍스트를 읽고 쓰는 동안 텍스트 인코딩 처리가 잘못되면 정보가 손실되고 읽을 수 없는 문자(예: null)가 실수로 포함되어 텍스트 구문 분석에 영향을 미칠 수 있습니다. 데이터를 올바르게 정렬하고 구조화되지 않은 데이터 또는 반 구조적 데이터에서 구조적 데이터를 추출할 수 있도록 텍스트 필드를 정리하려면 신중한 구문 분석 및 편집 작업이 필요할 수 있습니다.

**데이터 탐색**을 통해 초기에 데이터를 살펴볼 수 있습니다. 이 단계에서 다양한 데이터 문제를 파악하고 그에 맞는 적절한 방법을 적용하여 이러한 문제를 해결할 수 있습니다. 문제의 원인이 무엇인지, 문제가 어떻게 시작되었는지 등의 질문에 대한 답을 고민해 보는 것이 중요합니다. 이러한 고민은 문제 해결에 필요한 데이터 처리 단계를 결정하는 데에도 도움이 됩니다. 또한 데이터에서 얻은 이러한 통찰력을 사용하여 데이터 처리 작업의 우선 순위를 지정할 수 있습니다.

## 참조

>*데이터 마이닝: 개념 및 기술*, Third Edition, Morgan Kaufmann, 2011, Jiawei Han, Micheline Kamber 및 Jian Pei

<!---HONumber=AcomDC_0921_2016-->