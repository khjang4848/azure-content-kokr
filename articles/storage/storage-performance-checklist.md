<properties
	pageTitle="Azure 저장소 성능 및 확장성 검사 목록 | Microsoft Azure"
	description="성능이 뛰어난 응용 프로그램 개발 시 Azure 저장소에서 사용하기 위한 검증된 작업 방식에 대한 검사 목록."
	services="storage"
	documentationCenter=""
	authors="robinsh"
	manager="carmonm"
	editor="tysonn"/>

<tags
	ms.service="storage"
	ms.workload="storage"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="article"
	ms.date="08/03/2016"
	ms.author="robinsh"/>

# Microsoft Azure 저장소 성능 및 확장성 검사 목록

## 개요
Microsoft Azure 저장소 서비스가 출시된 이후 Microsoft는 이러한 서비스를 성능 기준에 맞는 방식으로 사용할 수 있도록 효율성이 검증된 다양한 작업 방식을 개발했습니다. 이 문서에는 이러한 작업 방식 중 가장 중요한 항목을 검사 목록 스타일의 목록으로 통합되어 있습니다. 이 문서에서는 응용 프로그램 개발자가 Azure 저장소와 관련하여 검증된 작업 방식을 사용하고 있는지를 확인하고, 도입을 고려해야 하는 기타 검증된 작업 방식을 파악하는 데 도움이 되는 정보를 제공합니다. 그러나 가능한 모든 성능 및 확장성 최적화 기능에 대해 다루지는 않으며, 큰 영향을 주지 않거나 광범위하게 적용할 수 없는 기능은 제외됩니다. 디자인 중에 응용 프로그램 동작을 예측할 수 없는 범위 내에서는 이러한 사항을 초기에 파악해 두면 성능 문제를 야기하는 디자인을 피하는 데 유용합니다.

Azure 저장소를 사용하는 모든 응용 프로그램 개발자는 시간을 할애하여 이 문서의 내용을 파악하고 자신이 개발한 응용 프로그램이 아래에 나와 있는 각각의 검증된 작업 방식을 따르는지를 확인해야 합니다.

## 검사 목록
이 문서에는 검증된 작업 방식이 다음과 같은 그룹으로 구성되어 있습니다. 검증된 작업 방식이 적용되는 대상은 다음과 같습니다.

-	모든 Azure 저장소 서비스(Blob, 테이블, 큐, 파일)
-	Blob
-	테이블
-	큐

|완료된|	영역|	Category|	질문
|----|------|-----------|-----------
||모든 서비스|	확장성 목표|[응용 프로그램이 확장성 목표에 도달하지 않도록 설계되어 있습니까?](#subheading1)
||모든 서비스|	확장성 목표|[명명 규칙이 부하 분산 향상에 맞게 설계되었습니까?](#subheading47)
||모든 서비스|	네트워킹|	[클라이언트 쪽 장치에서 필요한 성능을 달성할 수 있을 정도로 대역폭은 높고 대기 시간은 낮습니까?](#subheading2)
||모든 서비스|	네트워킹|	[클라이언트 쪽 장치의 링크 품질이 충분히 높습니까?](#subheading3)
||모든 서비스|	네트워킹|	[클라이언트 응용 프로그램이 저장소 계정 "근처"에 있습니까?](#subheading4)
||모든 서비스|	콘텐츠 배포|	[콘텐츠 배포를 위해 CDN을 사용합니까?](#subheading5)
||모든 서비스|	직접 클라이언트 액세스|	[SAS 및 CORS를 사용하여 프록시가 아닌 저장소에 직접 액세스를 허용합니까?](#subheading6)
||모든 서비스|	구성|	[응용 프로그램에서 반복적으로 사용되며 거의 변경되지 않는 데이터를 캐시합니까?](#subheading7)
||모든 서비스|	구성|	[응용 프로그램에서 업데이트를 일괄 처리(클라이언트 쪽에서 업데이트를 캐시한 다음 더 큰 집합으로 업로드)합니까?](#subheading8)
||모든 서비스|	.NET 구성|	[클라이언트가 충분한 수의 동시 연결을 사용하도록 구성했습니까?](#subheading9)
||모든 서비스|	.NET 구성|	[.NET이 충분한 수의 스레드를 사용하도록 구성했습니까?](#subheading10)
||모든 서비스|	.NET 구성|	[가비지 수집 기능이 개선된 .NET 4.5 이상을 사용 중입니까?](#subheading11)
||모든 서비스|	병렬 처리|	[클라이언트 기능이나 확장성 목표가 오버로드되지 않도록 병렬 처리의 경계를 적절하게 지정했습니까?](#subheading12)
||모든 서비스|	도구|	[Microsoft 제공 클라이언트 라이브러리와 도구의 최신 버전을 사용하고 있습니까?](#subheading13)
||모든 서비스|	다시 시도|	[제한 시간 및 오류 제한을 위한 지수 백오프 다시 시도 정책을 사용하고 있습니까?](#subheading14)
||모든 서비스|	다시 시도|	[응용 프로그램에서 다시 시도할 수 없는 오류 발생 시에는 작업을 다시 시도하지 않습니까?](#subheading15)
||Blob|	확장성 목표|	[동시에 단일 개체에 액세스하는 클라이언트가 많이 있습니까?](#subheading46)
||Blob|	확장성 목표|	[응용 프로그램에서 단일 Blob에 대한 대역폭 또는 작업의 확장성 목표가 유지됩니까?](#subheading16)
||Blob|	Blob 복사|	[Blob를 효율적으로 복사하고 있습니까?](#subheading17)
||Blob|	Blob 복사|	[대량 Blob 복사에 AzCopy를 사용하고 있습니까?](#subheading18)
||Blob|	Blob 복사|	[매우 많은 데이터를 전송하는 데 Azure 가져오기/내보내기를 사용하고 있습니까?](#subheading19)
||Blob|	메타데이터 사용|	[자주 사용되는 Blob 관련 메타데이터를 해당 메타데이터에 저장하고 있습니까?](#subheading20)
||Blob|	고속 업로드|	[Blob 하나를 빠르게 업로드하려는 경우 블록을 병렬로 업로드합니까?](#subheading21)
||Blob|	고속 업로드|	[Blob 여러 개를 빠르게 업로드하려는 경우 Blob를 병렬로 업로드합니까?](#subheading22)
||Blob|	올바른 Blob 유형|	[해당하는 경우 페이지 Blob 또는 블록 Blob를 사용합니까?](#subheading23)
||테이블|	확장성 목표|	[초당 엔터티의 확장 목표에 도달하고 있습니까?](#subheading24)
||테이블|	구성|	[테이블 요청에 JSON을 사용하고 있습니까?](#subheading25)
||테이블|	구성|	[소규모 요청의 성능을 개선하기 위해 Nagle을 해제했습니까?](#subheading26)
||테이블|	테이블 및 파티션|	[데이터를 적절하게 분할했습니까?](#subheading27)
||테이블|	핫 파티션|	[추가 전용 및 앞에 추가 전용 패턴을 지양하고 있습니까?](#subheading28)
||테이블|	핫 파티션|	[여러 파티션을 대상으로 삽입/업데이트를 수행합니까?](#subheading29)  
||테이블|	쿼리 범위|	[대부분의 경우에는 지점 쿼리를 사용하고 테이블 쿼리는 필요한 경우에만 사용하도록 스키마를 디자인했습니까?](#subheading30)
||테이블|	쿼리 밀도|	[일반적으로 쿼리가 응용 프로그램에서 사용할 행만 스캔하여 반환합니까?](#subheading31)
||테이블|	반환되는 데이터 제한|	[필요하지 않은 엔터티는 반환되지 않도록 필터링을 사용하고 있습니까?](#subheading32)
||테이블|	반환되는 데이터 제한|	[필요하지 않은 속성은 반환되지 않도록 프로젝션을 사용하고 있습니까?](#subheading33)
||테이블|	비정규화|	[데이터를 가져올 때 비효율적인 쿼리 또는 여러 읽기 요청을 방지하기 위해 데이터를 비정규화했습니까?](#subheading34)
||테이블|	삽입/업데이트/삭제|	[왕복 횟수를 줄이기 위해 동시에 수행할 수 있거나 트랜잭션 방식으로 수행해야 하는 요청을 일괄 처리하고 있습니까?](#subheading35)
||테이블|	삽입/업데이트/삭제|	[단순한 호출 대상(삽입 또는 업데이트) 결정을 위한 엔터티 검색을 지양하고 있습니까?](#subheading36)
||테이블|	삽입/업데이트/삭제|	[자주 함께 검색할 일련의 데이터를 여러 엔터티가 아닌 단일 엔터티에 속성으로 저장하는 것을 고려한 적이 있습니까?](#subheading37)
||테이블|	삽입/업데이트/삭제|	[배치로 쓸 수 있으며 항상 함께 검색할 엔터티(예: 시계열 데이터)에 대해 테이블이 아닌 Blob 사용을 고려한 적이 있습니까?](#subheading38)
||큐|	확장성 목표|	[초당 메시지의 확장 목표에 도달하고 있습니까?](#subheading39)
||큐|	구성|	[소규모 요청의 성능을 개선하기 위해 Nagle을 해제했습니까?](#subheading40)
||큐|	메시지 크기|	[큐 성능을 개선하기 위해 메시지를 압축합니까?](#subheading41)
||큐|	대량 검색|	[단일 "Get" 작업으로 여러 메시지를 검색합니까?](#subheading42)
||큐|	폴링 빈도|	[응용 프로그램의 체감 대기 시간을 단축할 수 있을 만큼 자주 폴링을 수행하고 있습니까?](#subheading43)
||큐|	메시지 업데이트|	[오류 발생 시 전체 메시지를 다시 처리하지 않아도 되도록 UpdateMessage를 사용하여 메시지 처리 진행률을 저장하고 있습니까?](#subheading44)
||큐|	아키텍처|	[장기 실행 작업을 중요 경로 외부에서만 실행하고 독립적으로 확장함으로써 큐를 통해 전체 응용 프로그램의 확장성을 높이고 있습니까?](#subheading45)


##<a name="allservices"></a>모든 서비스
이 섹션에서는 모든 Azure 저장소 서비스(Blob, 테이블, 큐 또는 파일) 사용 시 적용되는 검증된 작업 방식에 대해 설명합니다.

###<a name="subheading1"></a>확장성 목표
각 Azure 저장소 서비스에는 용량(GB), 전송 속도 및 대역폭에 대한 확장성 목표가 있습니다. 응용 프로그램이 확장성 목표에 도달하거나 목표를 초과하는 경우 트랜잭션 대기 시간이 길어지거나 제한이 증가할 수 있습니다. 저장소 서비스는 응용 프로그램을 제한할 때 일부 저장소 트랜잭션에 대해 "503 서버 작업 중" 또는 "500 작업 시간 초과" 오류 코드 반환을 시작합니다. 이 섹션에서는 확장성 목표 관련 문제를 해결하는 일반적인 방식을 설명하며, 특히 대역폭 확장성 목표 관련 작업 방식에 대해서도 설명합니다. 개별 저장소 서비스에 대해 다루는 이후 섹션에서는 다음과 같은 특정 서비스의 컨텍스트에서 확장성 목표에 대해 설명합니다.

-	[Blob 대역폭 및 초당 요청 수](#subheading16)
-	[초당 테이블 엔터티 수](#subheading24)
-	[초당 큐 메시지 수](#subheading39)

####<a name="sub1bandwidth"></a>모든 서비스에 대한 대역폭 확장성 목표
이 문서를 작성할 당시 미국의 GRS(지역 중복 저장소) 계정에 대한 대역폭 목표는 수신(저장소 계정으로 전송되는 데이터)의 경우 10Gbps(초당 기가비트)이고 송신(저장소 계정에서 전송하는 데이터)의 경우 20Gbps입니다. LRS(로컬 중복 저장소) 계정의 경우에는 수신의 경우 20Gbps, 송신의 경우 30Gbps로 제한이 좀 더 높습니다. 기타 국가의 대역폭 제한은 이보다 더 낮을 수 있습니다. 관련 정보는 [확장성 목표 페이지](http://msdn.microsoft.com/library/azure/dn249410.aspx)에서 확인할 수 있습니다. 저장소 중복 옵션에 대한 자세한 내용은 아래 [유용한 리소스](#sub1useful)의 링크를 참조하세요.

####확장성 목표에 도달했을 때 수행할 작업
응용 프로그램이 특정 저장소 계정의 확장성 목표에 도달한 경우 다음 방법 중 하나를 사용할 수 있습니다.

-	응용 프로그램이 확장성 목표에 도달하거나 목표를 초과한 원인이 되는 워크로드를 다시 고려합니다. 즉, 대역폭이나 용량을 더 적게 사용하거나 트랜잭션을 더 적게 수행하도록 해당 작업을 다시 디자인할 수 있는지를 파악합니다.
-	응용 프로그램에서 확장성 목표 중 하나를 초과해야 하는 경우에는 여러 저장소 계정을 만들고 해당 계정으로 응용 프로그램 데이터를 분할해야 합니다. 이러한 패턴을 사용하는 경우에는 향후 부하 분산을 위해 저장소 계정을 더 추가할 수 있도록 응용 프로그램을 디자인해야 합니다. 이 문서를 작성할 당시 각 Azure 구독은 저장소 계정을 100개까지 포함할 수 있습니다. 또한 저장소 계정에는 저장하거나 전송하는 데이터 또는 수행하는 트랜잭션과 관련된 사용 요금 외의 기타 비용은 없습니다.
-	응용 프로그램의 대역폭 목표에 도달한 경우 클라이언트의 데이터를 압축하여 저장소 서비스로 데이터를 보내는 데 필요한 대역폭을 줄일 수 있습니다. 이렇게 하면 대역폭을 줄이고 네트워크 성능을 개선할 수는 있지만, 몇 가지 좋지 않은 영향도 있을 수 있습니다. 그러므로 클라이언트에서 데이터를 압축하고 압축을 풀기 위한 추가 처리 요구 사항에 의해 발생하는 성능 관련 영향을 평가해야 합니다. 뿐만 아니라 압축된 데이터를 저장하는 경우 표준 도구를 사용해 저장된 데이터를 확인하기가 어려워질 수 있으므로 문제를 해결하기도 더 어려워질 수 있습니다.
-	응용 프로그램이 확장성 목표에 도달한 경우 다시 시도에 대해 지수 백오프를 사용 중인지 확인합니다([다시 시도](#subheading14) 참조). 위에서 설명한 방법 중 하나를 사용하여 확장성 목표에 도달하지 않도록 하는 것이 가장 좋지만, 지수 백오프를 사용하면 응용 프로그램이 빠르게 다시 시도를 계속하여 더욱 엄격한 제한이 적용되는 현상을 방지할 수 있습니다.

####유용한 리소스
다음 링크에서는 확장성 목표에 대한 추가 정보를 제공합니다.
-	확장성 목표에 대한 자세한 내용은 [Azure 저장소 확장성 및 성능 목표](storage-scalability-targets.md)를 참조하세요.
-	저장소 중복 옵션에 대한 내용은 [Azure 저장소 복제](storage-redundancy.md) 및 블로그 게시물 [Azure 저장소 중복 옵션 및 읽기 액세스 지역 중복 저장소](http://blogs.msdn.com/b/windowsazurestorage/archive/2013/12/11/introducing-read-access-geo-replicated-storage-ra-grs-for-windows-azure-storage.aspx)를 참조하세요.
-	Azure 서비스 가격에 대한 최신 정보는 [Azure 가격 책정](https://azure.microsoft.com/pricing/overview/)을 참조하세요.

###<a name="subheading47"></a>파티션 명명 규칙
Azure 저장소는 범위 기반 파티션 구성표를 사용하여 시스템을 확장하고 부하를 분산합니다. 파티션 키는 데이터를 범위로 파티션하는 데 사용되며 이러한 범위는 시스템 전체에서 부하가 분산됩니다. 다시 말해 어휘 순서(예: msftpayroll, msftperformance, msftemployees 등)와 같은 명명 규칙 또는 타임 스탬프(log20160101, log20160102, log20160102 등)를 사용할 경우 부하 분산 작업이 파티션을 작은 범위로 분할할 때까지 파티션이 동일한 파티션 서버에 함께 있을 수 있습니다. 예를 들어 컨테이너 내 모든 Blob는 이러한 Blob의 부하가 파티션 범위의 추가 리밸런싱을 요구하기 전까지 단일 서버가 지원할 수 있습니다. 마찬가지로, 이름이 어휘 순서로 정렬된 가벼운 부하의 계정 그룹도 하나 또는 전체 계정의 부하에서 여러 파티션 서버로 분할을 요구할 때까지 단일 서버가 지원할 수 있습니다. 각 부하 분산 작업은 작업 중 저장소 호출의 지연 시간에 영향을 미칠 수 있습니다. 파티션에 대한 트래픽 급증을 처리하는 시스템 기능은 부하 분산 작업이 시작되고 파티션 키 범위가 리밸런싱될 때까지 단일 파티션 서버의 확장성에 의해 제한될 수 있습니다.

이러한 작업의 빈도를 줄이려면 몇 가지 모범 사례를 따르십시오.

-	계정, 컨테이너, Blob, 테이블, 큐에 사용하는 명명 규칙을 자세히 확인합니다. 계정 이름에 요구 사항에 가장 적합한 해싱 함수를 사용하는 3자릿수 해시의 접두사를 추가해 보십시오.
-	타임스탬프 또는 숫자 식별자를 사용하여 데이터를 정리할 경우 추가만 가능한(또는 앞에만 추가할 수 있는) 트래픽 패턴을 사용하지 않아야 합니다. 이러한 패턴은 범위 기반 파티셔닝 시스템에 적합하지 않으며 모든 트래픽이 단일 파티션으로 이동하여 시스템이 부하 분산을 효과적으로 수행하지 못할 수 있습니다. 예를 들어 일상적 작업에서 타임스탬프(예: yyyymmdd)가 포함된 Blob 개체를 사용하는 경우 이러한 일상적 작업의 모든 트래픽이 단일 파티션 서버에서 지원하는 단일 개체로 전송될 수 있습니다. Blob당 한계와 파티션당 한계가 요구 사항을 충족하는지 확인하고 필요에 따라 이 작업을 여러 Blob으로 나누는 것을 고려해 보십시오. 마찬가지로 테이블에 시계열 데이터를 저장하는 경우 모든 트래픽이 키 네임스페이스의 마지막 부분으로 전송될 수 있습니다. 타임스탬프 또는 숫자 ID를 사용해야 하는 경우에는 3자릿수 해시로 접두사를 추가합니다. 타임스탬프의 경우에는 ssyyyymmdd와 같이 시간의 초 부분을 접두사로 추가합니다. 열거 및 쿼리 작업을 일상적으로 수행하는 경우 쿼리 수를 제한하는 해시 함수를 선택합니다. 다른 경우에는 임의의 접두사로도 충분할 수 있습니다.
-	Azure 저장소에 사용된 파티션 구성표에 대한 자세한 내용은 [여기](http://sigops.org/sosp/sosp11/current/2011-Cascais/printable/11-calder.pdf)에서 SOSP 백서를 읽으십시오.

###네트워킹
API 호출은 중요한 작업이기는 하지만 응용 프로그램의 실제 네트워크 제약 조건이 성능에 큰 영향을 주는 경우가 많습니다. 아래에서는 사용자에게 적용될 수 있는 몇 가지 제한에 대해 설명합니다.

####클라이언트 네트워크 기능
#####<a name="subheading2"></a>처리량
대역폭의 경우에는 클라이언트 기능에 문제가 있는 경우가 많습니다. 예를 들어 저장소 계정 하나가 수신 데이터 10Gbps 이상을 처리할 수 있더라도([대역폭 확장성 목표](#sub1bandwidth) 참조) "소규모" Azure 작업자 역할 인스턴스의 네트워크 속도는 약 100Mbps에 불과합니다. 대규모 Azure 인스턴스에는 용량이 더 많은 NIC가 포함되므로 컴퓨터 하나의 네트워크 제한을 높여야 하는 경우에는 더 큰 인스턴스나 더 많은 VM을 사용하는 것이 좋습니다. 온-프레미스 응용 프로그램에서 저장소 서비스에 액세스하는 경우에도 동일한 규칙이 적용됩니다. 즉, 클라이언트 장치의 네트워크 기능과 Azure 저장소 위치에 대한 네트워크 연결을 파악한 다음 필요에 따라 기능과 연결을 개선하거나 해당 기능 내에서 작동하도록 응용 프로그램을 디자인해야 합니다.

#####<a name="subheading3"></a>링크 속도
네트워크를 어떤 방식으로 사용하든 네트워크의 상태로 인해 오류와 패킷 손실이 발생하면 효율적인 처리량을 달성하는 시간이 길어집니다. WireShark 또는 NetMon을 사용하면 이 문제를 진단하는 데 도움이 될 수 있습니다.

#####유용한 리소스
가상 컴퓨터 크기 및 할당된 대역폭에 대한 자세한 내용은 [Windows VM 크기](../virtual-machines/virtual-machines-windows-sizes.md) 또는 [Linux VM 크기](../virtual-machines/virtual-machines-linux-sizes.md)를 참조하세요.

####<a name="subheading4"></a>위치
모든 분산 환경에서는 클라이언트를 서버 근처에 배치하면 성능을 최대화할 수 있습니다. Azure 저장소 액세스 시 대기 시간을 최소화하려는 경우에는 클라이언트를 같은 Azure 지역 내에 배치하는 것이 가장 좋습니다. 예를 들어 Azure 웹 사이트에서 Azure 저장소를 사용하는 경우 웹 사이트와 저장소를 모두 단일 하위 지역(예: 미국 서부 또는 동남 아시아) 내에 배치해야 합니다. 그러면 대기 시간과 비용이 감소합니다. 이 문서를 작성할 당시 단일 하위 지역 내의 대역폭 사용은 무료입니다.

모바일 장치 앱이나 온-프레미스 엔터프라이즈 서비스와 같이 클라이언트 응용 프로그램이 Azure 내에서 호스트되지 않는 경우에도 저장소 계정을 해당 계정에 액세스할 장치와 가까운 하위 지역에 배치하면 대체적으로 대기 시간이 짧아집니다. 클라이언트가 일부는 북아메리카에 있고 일부는 유럽에 있는 등 광범위하게 분산되어 있다면 여러 저장소 계정(하나는 북아메리카 지역에 있고 하나는 유럽 지역에 있음)을 사용해야 합니다. 이렇게 하면 두 지역 사용자의 대기 시간이 모두 짧아집니다. 일반적으로 응용 프로그램에서 개별 사용자 관련 데이터를 저장하며 저장소 계정 간에 데이터를 복제하지 않아도 되는 경우 이 방식을 보다 쉽게 구현할 수 있습니다. 콘텐츠를 광범위하게 배포하려는 경우에는 CDN을 사용하는 것이 좋습니다. 자세한 내용은 다음 섹션을 참조하세요.

###<a name="subheading5"></a>콘텐츠 배포
응용 프로그램이 같은 지역이나 여러 지역의 많은 사용자에게 같은 콘텐츠(예: 웹 사이트의 홈 페이지에 사용되는 제품 데모 비디오)를 제공해야 하는 경우가 있습니다. 이러한 경우에는 Azure CDN(콘텐츠 배달 네트워크)과 같은 CDN을 사용해야 합니다. Azure CDN은 데이터 출처로 Azure 저장소를 사용합니다. 단일 하위 지역에 있으며 짧은 대기 시간 내에 다른 하위 지역으로 콘텐츠를 배달할 수 없는 Azure 저장소 계정과는 달리 Azure CDN은 전 세계 여러 데이터 센터의 서버를 사용합니다. 또한 CDN은 일반적으로 단일 저장소 계정보다 더 높은 송신 제한을 지원합니다.

Azure CDN에 대한 자세한 내용은 [Azure CDN](https://azure.microsoft.com/services/cdn/)을 참조하세요.

###<a name="subheading6"></a>SAS 및 CORS 사용
사용자의 웹 브라우저나 휴대폰 앱에서 JavaScript와 같은 코드가 Azure 저장소의 데이터에 액세스하도록 권한을 부여해야 하는 경우 사용할 수 있는 방법 중 하나는 웹 역할에서 응용 프로그램을 프록시로 사용하는 것입니다. 즉, 사용자의 장치는 웹 역할에 인증하고 웹 역할은 다시 저장소 서비스에 인증합니다. 이러한 방식을 사용하면 안전하지 않은 장치에서 저장소 계정 키가 노출되는 상황을 방지할 수 있습니다. 그러나 사용자의 장치와 저장소 서비스 간에 전송되는 모든 데이터가 웹 역할을 통과해야 하므로 이 방식을 사용하는 경우 웹 역할에 큰 오버헤드가 발생합니다. SAS(공유 액세스 서명)를 경우에 따라 CORS(크로스-원본 자원 공유) 헤더와 함께 사용하면 저장소 서비스에 대해 웹 역할을 프록시로 사용하지 않아도 됩니다. SAS를 사용하는 경우 제한된 액세스 토큰을 통해 사용자 장치가 저장소 서비스에 직접 요청을 하도록 허용할 수 있습니다. 예를 들어 사용자가 응용 프로그램에 사진을 업로드하려는 경우 웹 역할이 이후 30분 동안 특정 Blob 또는 컨테이너에 대한 쓰기 권한을 부여하는 SAS 토큰을 생성한 다음 사용자 장치로 전송할 수 있습니다. 30분이 지나면 SAS 토큰은 만료됩니다.

일반적으로 브라우저는 특정 도메인의 웹 사이트에서 호스트하는 페이지의 JavaScript가 다른 도메인에 대해 "PUT"과 같은 특정 작업을 수행하도록 허용하지 않습니다. 예를 들어 "contosomarketing.cloudapp.net"에서 웹 역할을 호스트하는 경우 클라이언트 쪽 JavaScript를 사용해 "contosoproducts.blob.core.windows.net"에서 저장소 계정에 Blob을 업로드하려고 하면 브라우저의 "동일 원본 정책"으로 인해 해당 작업이 차단됩니다. CORS는 대상 도메인(여기서는 저장소 계정)이 원본 도메인(여기서는 웹 역할)에서 생성되는 요청을 신뢰함을 브라우저에 전달할 수 있도록 하는 브라우저 기능입니다.

이 두 기술을 사용하면 웹 응용 프로그램에서 불필요한 로드와 병목 현상을 방지할 수 있습니다.

####유용한 리소스
SAS에 대한 자세한 내용은 [공유 액세스 서명, 1부: SAS 모델 이해](storage-dotnet-shared-access-signature-part-1.md)를 참조하세요.

CORS에 대한 자세한 내용은 [Azure 저장소 서비스에 대한 CORS(Cross-Origin Resource Sharing) 지원](http://msdn.microsoft.com/library/azure/dn535601.aspx)을 참조하세요.

###구성
####<a name="subheading7"></a>데이터 가져오기
일반적으로는 서비스에서 데이터를 가져오는 횟수가 적을수록 좋습니다. 웹 역할에서 실행 중인 MVC 웹 응용 프로그램이 사용자에게 콘텐츠로 제공하기 위해 저장소 서비스에서 50MB의 Blob을 이미 검색했다고 가정해 보겠습니다. 이 응용 프로그램은 사용자가 요청할 때마다 같은 Blob을 검색할 수도 있고, 해당 Blob을 디스크에 로컬로 캐시한 다음 후속 사용자 요청에 대해 캐시된 버전을 다시 사용할 수도 있습니다. 또한 사용자가 데이터를 요청할 때 응용 프로그램은 수정 시간에 대한 조건부 헤더가 포함된 GET을 실행할 수도 있습니다. 이 경우 Blob이 수정되지 않았으면 전체 Blob을 가져오지 않습니다. 테이블 엔터티 사용 시에도 이와 같은 패턴을 적용할 수 있습니다.

Blob이 검색 후 잠시 동안 유효한 상태로 유지된다고 가정하며, 해당 시간 동안에는 Blob 수정 여부를 확인하지 않아도 되도록 응용 프로그램을 설정할 수 있습니다.

응용 프로그램에서 항상 사용하는 구성, 조회 및 기타 데이터는 캐시하면 매우 효율적입니다.

.NET을 사용하여 Blob 속성을 가져와 마지막으로 수정한 날짜를 확인하는 방법의 예는 [속성과 메타데이터 설정 및 검색](storage-properties-metadata.md)을 참조하세요. 조건부 다운로드에 대한 자세한 내용은 [Blob의 로컬 복사본을 조건부로 새로 고침](http://msdn.microsoft.com/library/azure/dd179371.aspx)을 참조하세요.

####<a name="subheading8"></a>데이터 일괄 업로드
데이터를 로컬로 집계한 다음 각 데이터 부분을 즉시 업로드하는 대신 주기적으로 일괄 업로드할 수 있는 응용 프로그램 시나리오가 있습니다. 예를 들어 웹 응용 프로그램이 작업의 로그 파일을 유지할 수 있습니다. 모든 작업이 수행될 때 해당 세부 정보를 테이블 엔터티로 업로드할 수도 있고(저장소 작업을 여러 번 수행해야 함), 로컬 로그 파일에 작업 세부 정보를 저장한 다음 모든 작업 세부 정보를 구분된 파일로 Blob에 주기적으로 업로드할 수도 있습니다. 각 로그 항목의 크기가 1KB이면 단일 "Put Blob" 트랜잭션에서 수천 개의 항목을 업로드할 수 있습니다. 단일 트랜잭션에서 크기가 최대 64MB인 Blob를 업로드할 수 있습니다. 물론, 업로드 전에 로컬 컴퓨터가 크래시할 경우 일부 로그 데이터가 손실될 수 있습니다. 따라서 응용 프로그램 개발자는 클라이언트 장치 또는 업로드 실패의 가능성을 고려하여 디자인해야 합니다. 단일 작업이 아닌 시간 범위에 대해 작업 데이터를 다운로드해야 하는 경우에는 테이블보다 Blob를 사용하는 것이 좋습니다.

###.NET 구성
이 섹션에서는 .NET Framework를 사용하는 경우 성능을 크게 개선하기 위해 사용할 수 있는 다양한 빠른 구성 설정을 소개합니다. 다른 언어를 사용하는 경우에는 선택한 언어에 비슷한 개념이 적용되는지를 확인하세요.

####<a name="subheading9"></a>기본 연결 제한 늘리기
.NET에서 다음 코드는 기본 연결 제한(일반적으로 클라이언트 환경에서는 2이고, 서버 환경에서는 10임)을 100으로 늘립니다. 일반적으로 이 값을 응용 프로그램에서 사용되는 대략적인 스레드 수로 설정해야 합니다.

	ServicePointManager.DefaultConnectionLimit = 100; //(Or More)  

연결을 열기 전에 연결 제한을 설정해야 합니다.

기타 프로그래밍 언어의 경우 해당 언어의 설명서에서 연결 제한을 설정하는 방법을 확인하세요.

자세한 내용은 블로그 게시물 [웹 서비스: 동시 연결](http://blogs.msdn.com/b/darrenj/archive/2005/03/07/386655.aspx)을 참조하세요.

####<a name="subheading10"></a>비동기 작업에서 동기 코드를 사용하는 경우 스레드 풀의 최소 스레드 수 늘리기
다음 코드를 사용하면 스레드 풀의 최소 스레드 수를 늘릴 수 있습니다.

	ThreadPool.SetMinThreads(100,100); //(Determine the right number for your application)  

자세한 내용은 [ThreadPool.SetMinThreads 메서드](http://msdn.microsoft.com/library/system.threading.threadpool.setminthreads%28v=vs.110%29.aspx)를 참조하세요.

####<a name="subheading11"></a>.NET 4.5 가비지 수집 기능 활용
클라이언트 응용 프로그램에 .NET 4.5를 사용하면 서버 가비지 수집 시 성능을 개선할 수 있습니다.

자세한 내용은 [.NET 4.5의 성능 개선 사항 개요](http://msdn.microsoft.com/magazine/hh882452.aspx)를 참조하세요.

###<a name="subheading12"></a>제한 없는 병렬 처리
병렬 처리가 성능을 개선하는 데 매우 효율적이기는 하지만, 제한 없는 병렬 처리(스레드 및/또는 병렬 요청 수에 제한이 없음)를 사용하여 데이터를 업로드 또는 다운로드하거나 여러 작업자를 사용하여 같은 저장소 계정의 여러 파티션(컨테이너, 큐 또는 테이블 파티션)에 액세스하거나 같은 파티션의 여러 항목에 액세스할 때는 주의해야 합니다. 병렬 처리에 제한이 없는 경우 응용 프로그램에서 클라이언트 장치의 기능 또는 저장소 계정의 확장성 목표를 초과하여 대기 시간이 길어지고 제한이 증가할 수 있습니다.

###<a name="subheading13"></a>저장소 클라이언트 라이브러리 및 도구
항상 Microsoft에서 제공하는 최신 클라이언트 라이브러리와 도구를 사용해야 합니다. 이 문서를 작성할 당시에는 .NET, Windows Phone, Windows Runtime, Java, C++의 클라이언트 라이브러리와 다른 언어의 미리 보기 라이브러리를 사용할 수 있습니다. 또한 Microsoft에서는 Azure 저장소 작업을 위해 PowerShell cmdlet 및 Azure CLI 명령도 출시했습니다. Microsoft는 성능을 고려하여 이러한 도구를 활발하게 개발하고, 최신 서비스 버전으로 해당 도구를 최신 상태로 유지하며, 해당 도구가 대부분의 검증된 작업 방식을 처리할 수 있는지를 내부적으로 확인하고 있습니다.

###다시 시도
####<a name="subheading14"></a>제한/서버 작업 중
저장소 서비스에서 응용 프로그램을 제한하거나 일시적인 상황으로 인해 요청을 처리하지 못해 "503 서버 작업 중" 메시지 또는 "500 시간 초과"를 반환하는 경우가 있습니다. 응용 프로그램에서 확장성 목표에 도달했거나 시스템이 처리량을 높이기 위해 분할된 데이터의 균형을 다시 조정하는 경우 이러한 현상이 발생할 수 있습니다. 클라이언트 응용 프로그램은 일반적으로 이러한 오류를 발생시키는 작업을 다시 시도해야 합니다. 동일한 요청을 나중에 시도하면 성공할 수 있습니다. 그러나 응용 프로그램이 확장성 목표에 도달하여 저장소 서비스에서 응용 프로그램을 제한하는 경우 또는 서비스가 다른 이유로 인해 요청을 처리하지 못한 경우에는 작업을 적극적으로 다시 시도하면 대개 문제가 악화됩니다. 따라서 지수 백오프를 사용해야 합니다. 클라이언트 라이브러리에서는 이 동작을 기본적으로 사용합니다. 예를 들어 응용 프로그램은 작업을 2초, 4초, 10초, 30초 후에 다시 시도한 다음 계속 실패하면 작업을 완전히 포기할 수 있습니다. 이 동작을 적용하면 서비스에 대한 응용 프로그램의 로드가 크게 감소하며 문제가 악화되지 않습니다.

연결 오류는 제한으로 인해 발생하는 것이 아니며 일시적인 것이므로 즉시 다시 시도할 수 있습니다.

####<a name="subheading15"></a>다시 시도할 수 없는 오류
클라이언트 라이브러리는 다시 시도할 수 있는 오류와 그렇지 않은 오류를 인식할 수 있습니다. 그러나 저장소 REST API에 대해 사용자 고유의 코드를 작성하는 경우 다시 시도해서는 안 되는 오류도 있다는 사실을 기억하세요. 예를 들어 400(잘못된 요청) 응답은 클라이언트 응용 프로그램이 형식이 잘못되어 처리할 수 없는 요청을 보냈음을 나타냅니다. 이 요청을 다시 보내면 매번 같은 응답이 반환되므로 다시 시도해도 아무런 의미가 없습니다. 저장소 REST API를 기준으로 코드를 직접 작성하는 경우에는 오류 코드의 의미와 각 오류 코드에 대해 작업을 적절하게 다시 시도하거나 시도하지 않는 방법을 파악해야 합니다.

####유용한 리소스
저장소 오류 코드에 대한 자세한 내용은 Microsoft Azure 웹 사이트의 [상태 및 오류 코드](http://msdn.microsoft.com/library/azure/dd179382.aspx)를 참조하세요.

##Blob
위에서 설명한 [모든 서비스](#allservices)에 대한 검증된 작업 방식 외에 Blob 서비스에만 적용되는 다음과 같은 검증된 작업 방식도 있습니다.

###Blob 관련 확장성 목표

####<a name="subheading46"></a>동시에 단일 개체를 액세스하는 여러 클라이언트
동시에 단일 개체에 액세스하는 많은 수의 클라이언트가 있는 경우 개체 기준 및 저장소 계정 기준 확장성 목표를 고려해야 합니다. 단일 개체에 액세스할 수 있는 클라이언트의 정확한 수는 동시에 해당 개체를 요청하는 클라이언트의 수, 개체의 크기, 네트워크 상태 등의 요인에 따라 달라집니다.

개체를 웹 사이트에서 제공된 이미지 또는 비디오와 같은 CDN을 통해 배포할 수 있는 경우 CDN을 사용해야 합니다. [여기](#subheading5)를 참조하세요.

데이터가 기밀인 과학 시뮬레이션 등의 기타 시나리오에서는 두 가지 옵션을 사용할 수 있습니다. 첫 번째는 워크로드 액세스를 스태거하면서 일정 기간 동안 개체에 액세스하거나 동시에 액세스하는 방식입니다. 또는 개체를 임시로 여러 저장소 계정으로 복사하여 저장소 계정 전체에서 개체당 총 IOPS를 늘릴 수 있습니다. 제한된 테스트에서 약 25개의 VM이 동시에 100GB Blob을 다운로드할 수 있다는 사실이 확인되었습니다(각 VM이 32개의 스레드를 사용하여 다운로드를 병렬화함). 100개의 클라이언트가 개체에 액세스해야 하는 경우 먼저 두 번째 저장소 계정으로 복사한 다음 처음 50개의 VM은 첫 번째 Blob에 액세스하도록 하고 두 번째 50개의 VM은 두 번째 Blob에 액세스하도록 합니다. 결과는 응용 프로그램 동작에 따라 다르므로 설계 중에 이 동작을 테스트해야 합니다.


####<a name="subheading16"></a>Blob당 대역폭 및 작업
최대 초당 60MB의 속도로 단일 Blob을 읽거나 Blob에 쓸 수 있습니다. 이 속도는 약 480Mbps이므로 대부분의 클라이언트 쪽 네트워크 기능을 초과합니다(클라이언트 장치의 실제 NIC 포함). 또한 단일 Blob는 요청을 초당 500개까지 지원합니다. 여러 클라이언트가 같은 Blob을 읽어야 해서 이 제한이 초과될 수 있는 경우에는 CDN을 사용해 Blob을 분산시켜야 합니다.

Blob의 목표 처리량에 대한 자세한 내용은 [Azure 저장소 확장성 및 성능 목표](storage-scalability-targets.md)를 참조하세요.

###Blob 복사 및 이동
####<a name="subheading17"></a>Blob 복사
저장소 REST API 버전 2012-02-12에는 유용한 계정 간 Blob 복사 기능이 도입되었습니다. 클라이언트 응용 프로그램은 다른 원본(다른 저장소 계정일 수 있음)의 Blob을 복사하도록 저장소 서비스에 명령한 다음 해당 서비스가 비동기식으로 복사를 수행하도록 할 수 있습니다. 이 경우 데이터를 다운로드 및 업로드하지 않아도 되므로 다른 저장소 계정에서 데이터를 마이그레이션할 때 응용 프로그램에 필요한 대역폭을 크게 줄일 수 있습니다.

그러나 저장소 계정 간에 복사할 때는 복사 완료 시간이 보장되지 않는다는 점을 고려해야 합니다. 응용 프로그램이 개발자의 제어 아래에서 Blob 복사를 빠르게 완료해야 하는 경우에는 Blob을 VM에 다운로드한 다음 대상으로 업로드하는 방식으로 복사하는 것이 더 효율적일 수 있습니다. 해당 사항을 완벽하게 예측하려면 같은 Azure 지역에서 실행되는 VM이 복사를 수행하도록 합니다. 그렇지 않으면 네트워크 상태가 복사 성능에 영향을 줄 수 있으며 대부분의 경우에는 영향을 주게 됩니다. 비동기 복사의 진행률을 프로그래밍 방식으로 모니터링할 수도 있습니다.

같은 저장소 계정 자체 내의 복사는 보통 빠르게 완료됩니다.

자세한 내용은 [Blob 복사](http://msdn.microsoft.com/library/azure/dd894037.aspx)를 참조하세요.

####<a name="subheading18"></a>AzCopy 사용
Azure Storage 팀은 여러 저장소 계정으로/계정에서/계정 간에 많은 Blob을 대량으로 전송하는 데 사용할 수 있는 명령줄 도구인 "AzCopy"를 공개했습니다. 이 도구는 이러한 시나리오용으로 최적화되어 있으며 높은 전송 속도를 제공할 수 있습니다. 대량 업로드, 다운로드 및 복사 시나리오에는 이 도구를 사용하는 것이 좋습니다. 이 도구에 대해 자세히 알아보고 도구를 다운로드하려면 [AzCopy 명령줄 유틸리티로 데이터 전송](storage-use-azcopy.md)을 참조하세요.

####<a name="subheading19"></a>Azure 가져오기/내보내기 서비스
1TB가 넘는 매우 많은 양의 데이터에 대해 Azure 저장소에서는 가져오기/내보내기 서비스를 제공합니다. 이 서비스를 사용하는 경우 하드 드라이브를 배송하여 Blob 저장소에서 데이터를 업로드하고 다운로드할 수 있습니다. 데이터를 하드 드라이브에 저장한 다음 업로드용으로 Microsoft에 보내거나 데이터 다운로드를 위해 빈 하드 드라이브를 Microsoft에 보낼 수 있습니다. 자세한 내용은 [Microsoft Azure 가져오기/내보내기 서비스를 사용하여 Blob 저장소에 데이터 전송](storage-import-export-service.md)을 참조하세요. 네트워크를 통해 많은 양의 데이터를 업로드/다운로드하는 것보다 이 서비스를 사용하는 것이 훨씬 더 효율적일 수 있습니다.

###<a name="subheading20"></a>메타데이터 사용
Blob 서비스는 HEAD 요청을 지원하며, 여기에는 Blob 관련 메타데이터가 포함될 수 있습니다. 예를 들어 응용 프로그램은 사진에서 EXIF 데이터를 추출해야 하는 경우 사진을 검색해 데이터를 추출할 수 있습니다. 대역폭을 줄이고 성능을 개선하려면 응용 프로그램이 사진을 업로드할 때 Blob의 메타데이터에 EXIF 데이터를 저장하면 됩니다. 그런 다음 HEAD 요청만 사용하여 메타데이터에서 EXIF 데이터를 검색함으로써, Blob을 읽을 때마다 EXIF 데이터를 추출하는 데 필요한 상당한 대역폭과 처리 시간을 줄일 수 있습니다. Blob의 전체 데이터가 아닌 메타데이터만 필요한 시나리오에서는 이러한 방식이 유용합니다. 메타데이터는 Blob당 8KB만 저장할 수 있으므로(이보다 많은 메타데이터를 저장하려는 요청은 Blob 서비스에서 허용되지 않음) 메타데이터 크기가 8KB를 초과하면 이 방식을 사용할 수 없습니다.

.NET을 사용하여 Blob의 메타데이터를 가져오는 방법의 예는 [속성과 메타데이터 설정 및 검색](storage-properties-metadata.md)을 참조하세요.

###고속 업로드
Blob을 빠르게 업로드하려면 답변할 첫 번째 질문은 "Blob을 하나 업로드합니까 아니면 여러 개 업로드합니까?"입니다. 아래 지침을 참고하여 시나리오에 따라 사용할 적절한 방법을 결정합니다.

####<a name="subheading21"></a>큰 Blob 하나를 빠르게 업로드
큰 Blob 하나를 빠르게 업로드하려는 경우 클라이언트 응용 프로그램은 블록이나 페이지를 병렬로 업로드해야 합니다. 이때 개별 Blob의 확장성 목표와 저장소 계정의 전체 확장성 목표를 모두 고려해야 합니다. Microsoft에서 제공하는 공식 RTM 저장소 클라이언트 라이브러리(.NET, Java)에는 이러한 작업을 수행하는 기능이 있습니다. 각 라이브러리에 대해 아래에 지정된 개체/속성을 사용하여 동시성 수준을 설정합니다.

-	.NET: 사용할 BlobRequestOptions 개체에 대해 ParallelOperationThreadCount를 설정합니다.
-	Java/Android: BlobRequestOptions.setConcurrentRequestCount()를 사용합니다.
-	Node.js: 요청 옵션 또는 Blob 서비스에 대해 parallelOperationThreadCount를 사용합니다.
-	C++: blob\_request\_options::set\_parallelism\_factor 메서드를 사용합니다.

####<a name="subheading22"></a>여러 Blob을 빠르게 업로드
Blob 여러 개를 빠르게 업로드하려면 Blob을 병렬로 업로드합니다. 이 방식은 병렬 블록 업로드를 통해 Blob을 하나씩 업로드하는 것보다 빠릅니다. 저장소 서비스의 여러 파티션으로 업로드가 분산되기 때문입니다. 단일 Blob은 초당 60MB(약 480Mbps)의 처리량만을 지원합니다. 이 문서를 작성할 당시 미국 기반 LRS 계정은 최대 20Gbps의 수신 속도를 지원합니다. 이 속도는 개별 Blob이 지원하는 처리량보다 훨씬 높습니다. 이 시나리오에서는 기본적으로 업로드를 병렬로 수행하는 [AzCopy](#subheading18)를 사용하는 것이 좋습니다.

###<a name="subheading23"></a>적절한 Blob 유형 선택
Azure 저장소는 두 가지 유형의 Blob 즉, *페이지* Blob과 *블록* Blob을 지원합니다. 지정된 사용 시나리오에 대해 선택하는 Blob 유형은 솔루션의 성능과 확장성에 영향을 줍니다. 블록 Blob은 많은 양의 데이터를 효율적으로 업로드하려는 경우 적절합니다. 예를 들어 클라이언트 응용 프로그램이 사진이나 동영상을 Blob 저장소에 업로드해야 할 수 있습니다. 페이지 Blob은 응용 프로그램이 데이터에 대해 임의 쓰기를 수행해야 하는 경우 적절합니다. 예를 들어 Azure VHD는 페이지 Blob으로 저장됩니다.

자세한 내용은 [블록 Blob, 추가 Blob 및 페이지 Blob 이해](http://msdn.microsoft.com/library/azure/ee691964.aspx)를 참조하세요.

##테이블
위에서 설명한 [모든 서비스](#allservices)에 대한 검증된 작업 방식 외에 테이블 서비스에만 적용되는 다음과 같은 검증된 작업 방식도 있습니다.

###<a name="subheading24"></a>테이블 관련 확장성 목표
전체 저장소 계정의 대역폭 제한 외에 테이블에만 적용되는 확장성 제한도 있습니다. 트래픽이 증가하면 시스템에서 부하를 분산하지만 트래픽이 갑자기 증가하면 그에 해당하는 처리량을 즉시 달성하지 못할 수도 있습니다. 트래픽 패턴이 갑작스럽게 변화하는 경우 저장소 서비스가 테이블의 부하를 자동으로 분산시키므로 해당 변화 기간 동안에는 제한 및/또는 시간 초과가 발생합니다. 일반적으로는 트래픽이 서서히 증가하면 시스템이 적절하게 부하를 분산할 수 있는 시간이 있으므로 더 나은 결과를 얻을 수 있습니다.

####초당 엔터티 수(계정)
계정의 테이블 액세스를 위한 확장성 제한은 초당 최대 2만 개 엔터티(각 1KB)입니다. 일반적으로는 삽입, 업데이트, 삭제 또는 스캔하는 각 엔터티가 이 목표 수 계산에 포함됩니다. 따라서 엔터티 100개가 포함된 일괄 삽입을 수행하면 엔터티가 100개로 계산됩니다. 마찬가지로 1,000개 엔터티를 스캔하여 5를 반환하는 쿼리의 경우 엔터티가 1,000개로 계산됩니다.

####초당 엔터티 수(파티션)
단일 파티션 내에서 테이블 액세스를 위한 확장성 목표는 초당 2,000개 엔터티(각 1KB)입니다. 파티션의 경우에도 이전 섹션에서 설명한 것과 같은 계산 방법이 사용됩니다.

###구성
이 섹션에서는 테이블 서비스에서 성능을 크게 개선하기 위해 사용할 수 있는 다양한 빠른 구성 설정을 소개합니다.

####<a name="subheading25"></a>JSON 사용
저장소 서비스 버전 2013-08-15부터 테이블 서비스에서는 테이블 데이터를 전송하는 데 XML 기반 AtomPub가 아닌 JSON을 사용할 수 있게 되었습니다. 이로 인해 페이로드 크기를 최대 75%까지 줄일 수 있으며 응용 프로그램의 성능을 크게 개선할 수 있습니다.

자세한 내용은 [Microsoft Azure 테이블: JSON 소개](http://blogs.msdn.com/b/windowsazurestorage/archive/2013/12/05/windows-azure-tables-introducing-json.aspx) 및 [테이블 서비스 작업의 페이로드 형식](http://msdn.microsoft.com/library/azure/dn535600.aspx)을 참조하세요.

####<a name="subheading26"></a>Nagle 해제
Nagle 알고리즘은 네트워크 성능을 개선하기 위한 수단으로 TCP/IP 네트워크에서 광범위하게 구현됩니다. 그러나 대화형 작업을 많이 수행하는 환경 등 일부 상황에서는 이 알고리즘이 적합하지 않습니다. Azure 저장소의 경우 Nagle 알고리즘은 테이블 및 큐 서비스에 대한 요청 성능을 떨어뜨릴 수 있으므로 가능한 경우에는 해제해야 합니다.

자세한 내용은 [소규모 요청에는 적합하지 않은 Nagle 알고리즘](http://blogs.msdn.com/b/windowsazurestorage/archive/2010/06/25/nagle-s-algorithm-is-not-friendly-towards-small-requests.aspx) 블로그 게시물을 참조하세요. 이 게시물에서는 테이블 및 큐 요청에서 Nagle 알고리즘이 부적절하게 상호 작용하는 이유와 클라이언트 응용 프로그램에서 Nagle 알고리즘을 사용하지 않도록 설정하는 방법에 대해 설명합니다.

###스키마
테이블 서비스의 성능에 영향을 주는 가장 큰 단일 요인은 데이터를 표시 및 쿼리하는 방법입니다. 각 응용 프로그램별로 다르기는 하지만 이 섹션에서는 다음 항목과 관련된 일반적인 검증된 작업 방식 중 몇 가지에 대해 간략하게 설명합니다.

-	테이블 디자인
-	효율적인 쿼리
-	효율적인 데이터 업데이트

####<a name="subheading27"></a>테이블 및 파티션
테이블은 파티션으로 구분됩니다. 파티션에 저장되는 모든 엔터티는 같은 파티션 키를 공유하며 해당 파티션 내에서 엔터티를 식별하는 데 사용되는 고유한 행 키를 포함합니다. 파티션을 사용하는 경우에는 이점도 있지만 확장성 제한도 적용됩니다.

-	이점: 최대 100개의 개별 저장소 작업(총 크기 제한 4MB)을 포함하는 단일 원자성 일괄 처리 트랜잭션에서 같은 파티션의 엔터티를 업데이트할 수 있습니다. 또한 같은 수의 엔터티를 검색한다고 가정할 때 여러 파티션에 분산된 데이터보다 단일 파티션 내의 데이터를 더 효율적으로 쿼리할 수 있습니다. 단, 테이블 데이터 쿼리와 관련된 추가 권장 사항을 확인해야 합니다.
-	확장성 제한: 파티션은 원자성 일괄 처리 트랜잭션을 지원하므로 단일 파티션에 저장된 엔터티에 대한 액세스는 부하 분산할 수 없습니다. 따라서 개별 테이블 파티션의 확장성 목표는 테이블 서비스에 대한 전체 확장성 목표보다 낮습니다.

테이블과 파티션의 이러한 특성을 고려할 때 다음과 같은 디자인 원칙을 적용해야 합니다.

-	클라이언트 응용 프로그램이 작업의 동일한 논리 단위에서 자주 업데이트하거나 쿼리하는 데이터는 같은 파티션에 배치해야 합니다. 이렇게 하는 이유는 응용 프로그램이 쓰기를 집계하기 때문일 수도 있고, 원자성 일괄 처리 작업을 활용하기 위해서일 수도 있습니다. 또한 단일 쿼리에서는 여러 파티션에 분산된 데이터보다 단일 파티션의 데이터를 더 효율적으로 쿼리할 수 있습니다.
-	클라이언트 응용 프로그램이 작업의 동일한 논리 단위에서 삽입/업데이트하거나 쿼리하지 않는 데이터(단일 쿼리 또는 일괄 처리 업데이트)는 별도의 파티션에 배치해야 합니다. 이때 주의해야 할 중요한 사항은, 단일 테이블의 파티션 키 수에는 제한이 없으므로 파티션 키가 매우 많아도 문제가 되지 않으며 성능에도 영향을 주지 않는다는 것입니다. 예를 들어 응용 프로그램이 사용자가 로그인하는 유명 웹 사이트인 경우에는 사용자 ID를 파티션 키로 사용하면 효율적일 수 있습니다.

####핫 파티션
핫 파티션은 계정에 대해 부적합한 비율의 트래픽을 받으며, 단일 파티션이므로 부하를 분산할 수 없는 파티션입니다. 일반적으로는 다음의 두 가지 방식 중 하나로 핫 파티션을 만듭니다.

#####<a name="subheading28"></a>추가 전용 및 앞에 추가 전용 패턴
"추가 전용" 패턴은 지정된 PK에 대한 모든/거의 모든 트래픽이 현재 시간에 따라 증가 및 감소하는 패턴입니다. 응용 프로그램이 현재 날짜를 로그 데이터의 파티션 키로 사용하는 경우를 예로 들 수 있습니다. 이 경우 모든 삽입 항목이 테이블의 마지막 파티션에 저장되며 모든 쓰기가 테이블 끝으로 이동하므로 시스템이 부하를 분산할 수 없게 됩니다. 해당 파티션에 대한 트래픽의 양이 파티션 수준 확장성 목표를 초과하면 제한이 적용됩니다. 따라서 테이블 전체에서 요청을 부하 분산할 수 있도록 트래픽이 여러 파티션으로 전송되도록 하는 것이 더 효율적입니다.

#####<a name="subheading29"></a>트래픽이 많은 데이터
사용 중인 파티션 구성표로 인해 단일 파티션에 다른 파티션보다 훨씬 많이 사용되는 데이터만 포함되는 경우에도 해당 파티션이 단일 파티션의 확장성 목표에 도달하면 제한이 적용될 수 있습니다. 따라서 파티션 구성표로 인해 확장성 목표에 도달하는 단일 파티션이 없는지를 확인하는 것이 좋습니다.

####쿼리
이 섹션에서는 테이블 서비스 쿼리와 관련하여 검증된 작업 방식에 대해 설명합니다.

#####<a name="subheading30"></a>쿼리 범위
여러 가지 방법으로 쿼리할 엔터티의 범위를 지정할 수 있습니다. 아래에서는 각 방법의 사용법에 대해 설명합니다.

일반적으로 스캔(단일 엔터티보다 큰 쿼리)은 수행하지 않는 것이 좋지만 스캔을 해야 하는 경우에는 불필요한 대량의 엔터티를 스캔하거나 반환하지 않도록 필요한 데이터만 스캔하도록 데이터를 구성합니다.

######지점 쿼리
지점 쿼리에서는 엔터티를 하나만 검색합니다. 이를 위해 검색할 엔터티의 파티션 키와 행 키를 모두 지정합니다. 이러한 쿼리는 매우 효율적이므로 가능한 경우 항상 사용해야 합니다.

######파티션 쿼리
파티션 쿼리는 공통 파티션 키를 공유하는 데이터 집합을 검색하는 쿼리입니다. 일반적으로 이 쿼리에서는 파티션 키와 함께 일부 엔터티 속성의 값 범위나 행 키 값의 범위를 지정합니다. 파티션 쿼리는 지점 쿼리보다 효율성이 낮으므로 꼭 필요할 때만 사용해야 합니다.

######테이블 쿼리
테이블 쿼리는 공통 파티션 키를 공유하지 않는 엔터티 집합을 검색하는 쿼리입니다. 이러한 쿼리는 효율적이지 않으므로 가능하면 사용하지 않아야 합니다.

#####<a name="subheading31"></a>쿼리 밀도
쿼리 효율성에 영향을 주는 또 다른 중요한 요인은 반환되는 집합을 찾기 위해 스캔한 엔터티 수와 비교한 반환된 엔터티 수입니다. 응용 프로그램에서 데이터 중 1%만 공유하는 속성 값에 대한 필터를 사용해 테이블 쿼리를 수행하는 경우 쿼리는 반환하는 1개의 엔터티당 100개의 엔터티를 스캔합니다. 앞에서 설명한 테이블 확장성 목표는 모두 검색된 엔터티 수와 관련되고 반환된 엔터티 수와는 관련이 없습니다. 낮은 쿼리 밀도는 쉽게 테이블 서비스가 응용 프로그램을 제한하도록 할 수 있습니다. 응용 프로그램이 사용자가 찾는 엔터티를 검색하기 위해 너무 많은 엔터티를 검색해야 하기 때문입니다. 이러한 현상을 방지하는 방법에 대한 자세한 내용은 아래의 [비정규화](#subheading34) 섹션을 참조하세요.

#####반환되는 데이터의 양 제한
######<a name="subheading32"></a>필터링
쿼리에서 클라이언트 응용 프로그램에 필요하지 않은 엔터티가 반환되는 경우 필터를 사용하여 반환되는 집합 크기를 줄일 수 있습니다. 클라이언트로 반환되지 않는 엔터티도 확장성 목표 계산에 포함되기는 하지만, 클라이언트 응용 프로그램이 처리해야 하는 엔터티의 수와 네트워크 페이로드 크기가 감소하므로 응용 프로그램의 성능은 개선됩니다. 단, 위의 [쿼리 밀도](#subheading31) 관련 참고 사항에서 설명한 것처럼 확장성 목표는 스캔하는 엔터티의 수와 관련된 것이므로 쿼리에서 많은 엔터티를 필터 처리하여 적은 수의 엔터티만 반환되더라도 제한은 계속 적용될 수 있습니다.

######<a name="subheading33"></a>프로젝션
클라이어트 응용 프로그램에 테이블 내 엔터티의 제한된 속성 집합만 필요한 경우에는 프로젝션을 사용하여 반환되는 데이터 집합의 크기를 제한할 수 있습니다. 이 경우 필터링과 마찬가지로 네트워크 로드 및 클라이언트 처리를 줄일 수 있습니다.

#####<a name="subheading34"></a>비정규화
관계형 데이터베이스를 사용할 때와는 달리, 테이블 데이터를 효율적으로 쿼리하는 검증된 작업 방식에서는 데이터를 비정규화해야 합니다. 즉, 대량의 엔터티를 스캔하여 응용 프로그램에 필요한 데이터를 찾는 대신 여러 엔터티에서 같은 데이터를 복제(데이터를 찾는 데 사용할 수 있는 각 키에 대해 하나씩)하여 클라이언트에 필요한 데이터를 찾기 위해 쿼리가 스캔해야 하는 엔터티의 수를 최소화해야 합니다. 예를 들어 전자 상거래 웹 사이트에서는 고객 ID(특정 고객의 주문 정보 확인) 및 날짜(특정 날짜의 주문 정보 확인)를 모두 기준으로 사용하여 주문으로 찾을 수 있습니다. 테이블 저장소에서는 엔터티 또는 엔터티에 대한 참조를 두 번 저장하는 것이 가장 좋습니다. 방금 설명한 예의 경우 엔터티를 고객 ID별로 쉽게 찾을 수 있도록 테이블 이름/PK/RK와 함께 한 번, 그리고 날짜별로 쉽게 찾을 수 있도록 다시 한 번 저장하는 것이 좋습니다.

####삽입/업데이트/삭제
이 섹션에서는 테이블 서비스에 저장된 엔터티 수정을 위한 검증된 작업 방식에 대해 설명합니다.

#####<a name="subheading35"></a>일괄 처리
Azure 저장소에서는 일괄 처리 트랜잭션을 ETG(엔터티 그룹 트랜잭션)라고 합니다. ETG 내의 모든 작업은 단일 파티션의 단일 테이블에 있어야 합니다. 가능한 경우에는 ETG를 사용하여 삽입, 업데이트 및 삭제를 일괄로 수행합니다. 그러면 클라이언트 응용 프로그램에서 서버로의 왕복 횟수와 청구 가능한 트랜잭션의 수가 줄어듭니다. ETG는 요금 청구 시 단일 트랜잭션으로 계산되며 저장소 작업을 100개까지 포함할 수 있습니다. 또한 원자성 업데이트가 가능하므로 단일 ETG 내에서는 모든 작업이 성공하거나 실패합니다. 모바일 장치와 같이 대기 시간이 긴 환경에서는 ETG를 사용하면 매우 효율적입니다.

#####<a name="subheading36"></a>Upsert
가능한 경우에는 항상 테이블 **Upsert** 작업을 사용합니다. **Upsert**에는 두 가지 유형이 있으며, 두 유형 모두 기존의 **Insert** 및 **Update** 작업보다는 효율적일 수 있습니다.

-	**InsertOrMerge**: 엔터티 속성 중 일부를 업로드해야 하는데 엔터티가 이미 있는지 여부가 확실치 않으면 이 작업을 사용합니다. 엔터티가 있는 경우 이 작업을 수행하면 **Upsert** 작업에 포함된 속성은 업데이트되고 기존의 모든 속성은 그대로 유지됩니다. 엔터티가 없으면 새 엔터티가 삽입됩니다. 이 작업은 변경되는 속성만 업데이트하면 되므로 쿼리에서 프로젝션을 사용하는 것과 비슷합니다.
-	**InsertOrReplace**: 완전히 새로운 엔터티를 업로드해야 하는데 엔터티가 이미 있는지 여부가 확실치 않으면 이 옵션을 사용합니다. 이 작업을 수행하면 이전 엔터티를 완전히 덮어쓰므로 새로 업로드하는 엔터티가 정확함이 확실한 경우에만 이 작업을 수행해야 합니다. 예를 들어 응용 프로그램이 사용자의 위치 데이터를 이전에 저장했는지 여부에 관계없이 사용자의 현재 위치를 저장하는 엔터티를 업데이트하려고 하며, 새 위치 엔터티가 완전하고 이전 엔터티의 정보는 전혀 필요하지 않은 경우 이 작업을 수행할 수 있습니다.

#####<a name="subheading37"></a>단일 엔터티에 데이터 계열 저장
경우에 따라 응용 프로그램은 자주 한꺼번에 검색해야 하는 데이터 계열을 저장합니다. 예를 들어 응용 프로그램은 지난 24시간의 데이터에 대한 롤링 차트를 그리기 위해 시간에 따른 CPU 사용량을 추적할 수 있습니다. 이 경우 사용할 수 있는 한 가지 방법은 시간당 테이블 엔터티 하나를 저장하는 것입니다. 이때 각 엔터티는 특정 시간을 나타내며 해당 시간의 CPU 사용량을 저장합니다. 이 데이터를 그리려면 응용 프로그램이 가장 최근의 24시간에 해당하는 데이터를 포함하는 엔터티를 검색해야 합니다.

또는 응용 프로그램은 단일 엔터티의 별도 속성으로 매시간의 CPU 사용량을 저장할 수 있습니다. 매시간을 업데이트하기 위해 응용 프로그램은 단일 **InsertOrMerge Upsert** 호출을 사용하여 최근 시간에 대한 값을 업데이트할 수 있습니다. 이 경우 응용 프로그램은 데이터를 그리기 위해 24시간 동안의 엔터티가 아닌 엔터티 하나만 검색하면 되므로 쿼리의 효율성이 매우 높아집니다(위의 [쿼리 범위](#subheading30) 설명 참조).

#####<a name="subheading38"></a>Blob에 구조적 데이터 저장
구조적 데이터를 테이블에 저장해야 하는 경우도 있지만 엔터티 범위는 항상 함께 검색되며 일괄로 삽입할 수 있습니다. 이와 관련한 좋은 예가 로그 파일입니다. 몇 분 동안의 로그를 일괄로 생성하여 삽입할 수 있으며 항상 몇 분 동안의 로그를 한 번에 검색할 수도 있습니다. 성능 측면에서는 테이블 대신 Blob을 사용하는 것이 보다 효율적입니다. 기록/반환되는 개체 수를 크게 줄일 수 있을 뿐 아니라 일반적으로 수행해야 하는 요청 수도 줄일 수 있기 때문입니다.

##큐
###<a name=subheading39"></a>확장성 제한
단일 큐는 초당 약 2,000개의 메시지(각각 1KB)를 처리할 수 있습니다(여기서는 각 AddMessage, GetMessage 및 DeleteMessage를 메시지로 계산). 응용 프로그램에 이 처리량이 부족한 경우 큐를 여러 개 사용하여 메시지를 분산해야 합니다.

[Azure 저장소 확장성 및 성능 목표](storage-scalability-targets.md)에서 현재 확장성 목표를 봅니다.

###<a name=subheading40"></a>Nagle 해제
Nagle 알고리즘에 대해 설명하는 테이블 구성 섹션을 참조하세요. Nagle 알고리즘은 대개 큐 요청 성능을 떨어뜨리므로 사용하지 않도록 설정해야 합니다.

###<a name=subheading41"></a>메시지 크기
메시지 크기가 증가함에 따라 큐 성능 및 확장성은 감소합니다. 그러므로 받는 사람이 메시지에서 필요로 하는 정보만 포함해야 합니다.

###<a name=subheading42"></a>일괄 검색
단일 작업에서 큐의 메시지를 32개까지 검색할 수 있습니다. 따라서 클라이언트 응용 프로그램으로부터의 왕복 횟수를 줄일 수 있으므로 모바일 장치 등 대기 시간이 긴 환경에서 특히 유용합니다.

###<a name=subheading43"></a>큐 폴링 간격
대부분의 응용 프로그램은 큐에서 메시지를 폴링하는데 이는 해당 응용 프로그램에 대한 트랜잭션의 최대 소스 중 하나일 수 있습니다. 폴링 간격은 현명하게 선택하세요. 너무 자주 폴링하면 응용 프로그램이 큐의 확장성 목표에 근접할 수 있습니다. 그러나 0.01달러(작성 시점의 경우)로 200,000개의 트랜잭션을 처리하는 단일 프로세서가 1초에 한 번씩 폴링할 경우 한 달에 15센트 미만이 소요되므로 일반적으로 비용은 폴링 간격을 선택하는 데 영향을 미치는 요소가 아닙니다.

최신 비용 정보는 [Azure Storage 가격 책정](https://azure.microsoft.com/pricing/details/storage/)을 참조하세요.

###<a name=subheading44"></a>UpdateMessage
**UpdateMessage**를 사용하면 표시 안 함 시간 제한을 늘리거나 메시지의 상태 정보를 업데이트할 수 있습니다. 이 기능은 유용하기는 하지만 각 **UpdateMessage** 작업이 확장성 목표 계산에 포함된다는 점을 기억해야 합니다. 그러나 각 작업 단계가 완료되면 작업을 다음 큐에 순서대로 전달하는 워크플로보다는 UpdateMessage 작업이 훨씬 더 효율적인 방식일 수 있습니다. **UpdateMessage** 작업을 사용하는 경우 응용 프로그램이 단계가 완료될 때마다 작업의 다음 단계를 위해 메시지를 다시 큐에 대기시키는 대신 메시지에 작업 상태를 저장한 다음 작업을 계속할 수 있습니다.

자세한 내용은 [방법: 대기 중인 메시지의 콘텐츠 변경](storage-dotnet-how-to-use-queues.md#change-the-contents-of-a-queued-message) 문서를 참조하세요.

###<a name=subheading45"></a>응용 프로그램 아키텍처
응용 프로그램 아키텍처를 확장 가능하게 설정하려면 큐를 사용해야 합니다. 다음 목록에는 큐를 사용하여 응용 프로그램의 확장성을 높이는 몇 가지 방법이 나와 있습니다.

-	큐를 사용하여 응용 프로그램에서 워크로드를 처리하고 원활하게 진행하기 위해 작업 백로그를 만들 수 있습니다. 예를 들어 업로드된 이미지 크기를 조정하는 등 프로세서를 많이 사용하는 작업을 수행하기 위한 사용자의 요청을 큐에 대기시킬 수 있습니다.
-	큐를 사용하여 응용 프로그램의 각 부분을 독립적으로 확장 가능하도록 분리할 수 있습니다. 예를 들어 웹 프런트 엔드에서 나중에 분석 및 저장하기 위해 사용자의 설문 조사 결과를 큐에 저장할 수 있습니다. 필요한 경우 큐 데이터를 처리하기 위해 작업자 역할 인스턴스를 더 추가할 수 있습니다.

##결론
이 문서에서는 Azure 저장소 사용 시 성능을 최적화하기 위한 가장 일반적인 검증된 작업 방식 중 일부에 대해 설명했습니다. 모든 응용 프로그램 개발자는 Azure 저장소를 사용하는 응용 프로그램의 성능을 높일 수 있도록 위에서 설명한 각 작업 방식을 기준으로 응용 프로그램을 평가한 다음 권장 사항을 적용하는 것이 좋습니다.

<!---HONumber=AcomDC_0914_2016-->